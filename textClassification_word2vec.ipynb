{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, use the pretrained word2vec model based on 6m patent dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_model = KeyedVectors.load_word2vec_format('../../../NLP_Patent_Project/model_ver2.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the average vector to represent each abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_vector(word2vec_model, words):\n",
    "    # remove out-of-vocabulary words\n",
    "    words = [word for word in words if word in word2vec_model.vocab]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(word2vec_model[words], axis=0)\n",
    "    else:\n",
    "        return []\n",
    "#print (get_mean_vector(word2vec_model, words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the prepared keywords from the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for the notebook crash\n",
    "keywords_df = pd.DataFrame(pd.read_csv('uspto_2m_keywords.tsv', sep='\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Title</th>\n",
       "      <th>pid</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G05B</td>\n",
       "      <td>an apparatus for generating a saddle shaped tr...</td>\n",
       "      <td>saddle shaped trajectory generator for two int...</td>\n",
       "      <td>8536817</td>\n",
       "      <td>apparatus, saddle, trajectory, intersection, c...</td>\n",
       "      <td>generate, shape, motorize, connect, intersect,...</td>\n",
       "      <td>two cylindrical conduit, motorize axial module...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H01L</td>\n",
       "      <td>an apparatus for generating a saddle shaped tr...</td>\n",
       "      <td>saddle shaped trajectory generator for two int...</td>\n",
       "      <td>8536817</td>\n",
       "      <td>apparatus, saddle, trajectory, intersection, c...</td>\n",
       "      <td>generate, shape, motorize, connect, intersect,...</td>\n",
       "      <td>two cylindrical conduit, motorize axial module...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A61M</td>\n",
       "      <td>the present invention provides apparatus and m...</td>\n",
       "      <td>balloon insertion apparatus and method of seal...</td>\n",
       "      <td>8382794</td>\n",
       "      <td>apparatus, tissue, introducer, sheath, side, p...</td>\n",
       "      <td>provide, close, puncture, enable, seal</td>\n",
       "      <td>internal tissue puncture site, introducer shea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01K</td>\n",
       "      <td>a restraint system for an animal comprising a ...</td>\n",
       "      <td>retractable leash and restraint assembly</td>\n",
       "      <td>8474414</td>\n",
       "      <td>restraint, system, animal, collar, assembly, l...</td>\n",
       "      <td>comprise, adapt, secure, define, connect</td>\n",
       "      <td>extended configuration, restraint assembly, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B29C</td>\n",
       "      <td>a container or tray having various features th...</td>\n",
       "      <td>container having a rim or other feature encaps...</td>\n",
       "      <td>8540111</td>\n",
       "      <td>container, tray, feature, comprise, sidewall, ...</td>\n",
       "      <td>correspond, connect, mold, encapsulate, extend...</td>\n",
       "      <td>bottom surface, top surface, second region con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           Abstract  \\\n",
       "0   G05B  an apparatus for generating a saddle shaped tr...   \n",
       "1   H01L  an apparatus for generating a saddle shaped tr...   \n",
       "2   A61M  the present invention provides apparatus and m...   \n",
       "3   A01K  a restraint system for an animal comprising a ...   \n",
       "4   B29C  a container or tray having various features th...   \n",
       "\n",
       "                                               Title      pid  \\\n",
       "0  saddle shaped trajectory generator for two int...  8536817   \n",
       "1  saddle shaped trajectory generator for two int...  8536817   \n",
       "2  balloon insertion apparatus and method of seal...  8382794   \n",
       "3           retractable leash and restraint assembly  8474414   \n",
       "4  container having a rim or other feature encaps...  8540111   \n",
       "\n",
       "                                                noun  \\\n",
       "0  apparatus, saddle, trajectory, intersection, c...   \n",
       "1  apparatus, saddle, trajectory, intersection, c...   \n",
       "2  apparatus, tissue, introducer, sheath, side, p...   \n",
       "3  restraint, system, animal, collar, assembly, l...   \n",
       "4  container, tray, feature, comprise, sidewall, ...   \n",
       "\n",
       "                                                verb  \\\n",
       "0  generate, shape, motorize, connect, intersect,...   \n",
       "1  generate, shape, motorize, connect, intersect,...   \n",
       "2             provide, close, puncture, enable, seal   \n",
       "3           comprise, adapt, secure, define, connect   \n",
       "4  correspond, connect, mold, encapsulate, extend...   \n",
       "\n",
       "                                             phrases  \n",
       "0  two cylindrical conduit, motorize axial module...  \n",
       "1  two cylindrical conduit, motorize axial module...  \n",
       "2  internal tissue puncture site, introducer shea...  \n",
       "3  extended configuration, restraint assembly, st...  \n",
       "4  bottom surface, top surface, second region con...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove invalid classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678887"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the valid list of classes\n",
    "class_df = pd.DataFrame(pd.read_csv('ipc4_descriptions.csv', sep=','))\n",
    "class_list = list(class_df['Class'])\n",
    "vaild_df = keywords_df[~keywords_df['label'].isin(class_list)]\n",
    "len(vaild_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we only keep noun and verb columns for creating vectors for each patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H01L</td>\n",
       "      <td>apparatus, saddle, trajectory, intersection, c...</td>\n",
       "      <td>generate, shape, motorize, connect, intersect,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B65D</td>\n",
       "      <td>container, tray, feature, comprise, sidewall, ...</td>\n",
       "      <td>correspond, connect, mold, encapsulate, extend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A61K</td>\n",
       "      <td>compound, pharmaceutical, composition, cancer,...</td>\n",
       "      <td>screen, identify, treat, prevent, disclose, af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>H01L</td>\n",
       "      <td>pattern, structure, insulating, interlayer, su...</td>\n",
       "      <td>form, etch, extend, block, electroplate, polis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>G07C</td>\n",
       "      <td>information, event, combustion, engine, igniti...</td>\n",
       "      <td>log, arrange, implement, comprise, incremente,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                               noun  \\\n",
       "1    H01L  apparatus, saddle, trajectory, intersection, c...   \n",
       "5    B65D  container, tray, feature, comprise, sidewall, ...   \n",
       "8    A61K  compound, pharmaceutical, composition, cancer,...   \n",
       "10   H01L  pattern, structure, insulating, interlayer, su...   \n",
       "17   G07C  information, event, combustion, engine, igniti...   \n",
       "\n",
       "                                                 verb  \n",
       "1   generate, shape, motorize, connect, intersect,...  \n",
       "5   correspond, connect, mold, encapsulate, extend...  \n",
       "8   screen, identify, treat, prevent, disclose, af...  \n",
       "10  form, etch, extend, block, electroplate, polis...  \n",
       "17  log, arrange, implement, comprise, incremente,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_words_df = vaild_df.drop(['Title', 'Abstract', 'pid', 'phrases'], axis = 1)\n",
    "label_words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine noun and verb columns and generate words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_words_df['words'] = label_words_df['noun'] + ', ' + label_words_df['verb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_words_df = label_words_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose fixed number of patents for each class randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 1000        # sample size\n",
    "replace = True  # cannot choose False, since some classes do not have 100 samples\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "sub_df = label_words_df.groupby('label', as_index=False).apply(fn)\n",
    "y = sub_df['label']\n",
    "len(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag = 0\n",
    "abstr_vectors = []\n",
    "for row in sub_df.itertuples():\n",
    "    words = set(x.strip() for x in row[4].split(','))\n",
    "    vec = get_mean_vector(word2vec_model, words)\n",
    "    abstr_vectors.append(vec)\n",
    "input_vectors = np.array(abstr_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we cannot use Naive Bayes classifier, since the vectors contain negative values.\n",
    "\n",
    "In our word2vec model, we only chose 100 dimension, which might lead to bad results.\n",
    "\n",
    "Logistic regression method is better than others. We should try it with tfidf matrix.\n",
    "\n",
    "Following work: \n",
    "\n",
    "1) Use Doc2vec to represent features, with the same classifiers, and compare the results.\n",
    "\n",
    "2) Train better word2vec models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_vectors, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 288.45141196250916 seconds ---\n",
      "Random Forest accuracy 0.719563492063492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "start_time = time.time()\n",
    "rfc = RandomForestClassifier(n_jobs=8, n_estimators=20, random_state=9, class_weight='balanced')\n",
    "model = rfc.fit(X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('Random Forest accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yan/anaconda3/envs/py3-tf2/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 139.00281810760498 seconds ---\n",
      "SVM_SGD accuracy 0.267484126984127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "sgd = SGDClassifier(n_jobs=4, random_state=99)\n",
    "model = sgd.fit(X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('SVM_SGD accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "start_time = time.time()\n",
    "svc = LinearSVC()\n",
    "model = svc.fit(X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "y_pred = model.predict(X_test)\n",
    "print('SVM accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yan/anaconda3/envs/py3-tf2/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 12250.07357120514 seconds ---\n",
      "Logistic regression accuracy 0.11524758610006712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "start_time = time.time()\n",
    "lrc = LogisticRegression(C=0.5, random_state=9, solver='sag', multi_class='multinomial', n_jobs=8)\n",
    "model = lrc.fit(X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "y_pred = model.predict(X_test)\n",
    "print('Logistic regression accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 504000 samples, validate on 126000 samples\n",
      "Epoch 1/10\n",
      "504000/504000 [==============================] - 19s 38us/sample - loss: 4.0728 - accuracy: 0.2166 - val_loss: 3.5077 - val_accuracy: 0.2815\n",
      "Epoch 2/10\n",
      "504000/504000 [==============================] - 18s 35us/sample - loss: 3.3501 - accuracy: 0.3026 - val_loss: 3.2610 - val_accuracy: 0.3113\n",
      "Epoch 3/10\n",
      "504000/504000 [==============================] - 18s 36us/sample - loss: 3.1780 - accuracy: 0.3270 - val_loss: 3.1514 - val_accuracy: 0.3315\n",
      "Epoch 4/10\n",
      "504000/504000 [==============================] - 18s 36us/sample - loss: 3.0897 - accuracy: 0.3406 - val_loss: 3.0943 - val_accuracy: 0.3404\n",
      "Epoch 5/10\n",
      "504000/504000 [==============================] - 18s 35us/sample - loss: 3.0353 - accuracy: 0.3496 - val_loss: 3.0538 - val_accuracy: 0.3473\n",
      "Epoch 6/10\n",
      "504000/504000 [==============================] - 18s 36us/sample - loss: 2.9980 - accuracy: 0.3561 - val_loss: 3.0290 - val_accuracy: 0.3512\n",
      "Epoch 7/10\n",
      "504000/504000 [==============================] - 18s 35us/sample - loss: 2.9711 - accuracy: 0.3601 - val_loss: 3.0095 - val_accuracy: 0.3554\n",
      "Epoch 8/10\n",
      "504000/504000 [==============================] - 18s 35us/sample - loss: 2.9505 - accuracy: 0.3639 - val_loss: 2.9953 - val_accuracy: 0.3559\n",
      "Epoch 9/10\n",
      "504000/504000 [==============================] - 18s 35us/sample - loss: 2.9350 - accuracy: 0.3669 - val_loss: 2.9847 - val_accuracy: 0.3586\n",
      "Epoch 10/10\n",
      "504000/504000 [==============================] - 18s 36us/sample - loss: 2.9222 - accuracy: 0.3690 - val_loss: 2.9751 - val_accuracy: 0.3600\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import models, layers, callbacks\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "\n",
    "def build_mlp_model(units, n_layers, last_layer_activation, hidden_layer_activation, input_shape, dropout_rate, numOfclasses):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    #hidden layers\n",
    "    for _ in range(n_layers-1):\n",
    "        model.add(layers.Dense(units=units, activation=hidden_layer_activation, \n",
    "                               kernel_initializer='glorot_uniform', input_dim = input_shape))\n",
    "        model.add(layers.Dropout(rate=dropout_rate))\n",
    "    \n",
    "    #output layer\n",
    "    model.add(layers.Dense(units=numOfclasses, activation=last_layer_activation))\n",
    "    return model\n",
    "\n",
    "numOfclasses = len(sub_df.groupby('label'))\n",
    "last_layer_activation = 'softmax'\n",
    "hidden_layer_activation = 'relu'\n",
    "input_shape = X_train.shape[1]\n",
    "dropout_rate = 0.5\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "n_layers = 1\n",
    "units = 32\n",
    "batch_size = 128\n",
    "\n",
    "model = build_mlp_model(units, n_layers, last_layer_activation, hidden_layer_activation, input_shape, dropout_rate, numOfclasses)\n",
    "model.compile(loss=loss, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#use early-stopping\n",
    "callback_early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), \n",
    "                    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-tf2]",
   "language": "python",
   "name": "conda-env-py3-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
